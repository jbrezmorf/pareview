<ServerManagerConfiguration>
  <ProxyGroup name="sources">
    <SourceProxy name="EclipseReader_1" class="vtkPythonProgrammableFilter" label="Eclipse EGRID and UNRST reader">
      <Documentation
        long_help="Read mesh in EGRID format and time dependent data from UNRST output files."
        short_help="Read mesh in EGRID format and time dependent data from UNRST output files.">
      </Documentation>

      <StringVectorProperty
            name="FileName"
            label="FileName"
            initial_string="FileName"
            animateable="1"
            command="SetParameter"
            default_values=""
            number_of_elements="1"
            panel_visibility="never">
            <FileListDomain name="files"/>
            <Documentation>
                This property specifies the file name for the reader.
            </Documentation>
      </StringVectorProperty>
      
      <!-- Set output grid type: vtkMultiblockDataSet -->
      <IntVectorProperty command="SetOutputDataSetType"
                         default_values="13"
                         name="OutputDataSetType"
                         number_of_elements="1"
                         panel_visibility="never">
        <Documentation>The value of this property determines the dataset type
        for the output of the programmable filter.</Documentation>
      </IntVectorProperty>

      <StringVectorProperty
        name="Script"
        command="SetScript"
        number_of_elements="1"
        default_values="import threading&#xA;&#xA;if (not hasattr(self,&quot;info_done_event&quot;)):&#xA;    self.info_done_event=threading.Event()&#xA;&#xA;self.info_done_event.wait(1)    &#xA;# main RequestData script  &#xA;self.code.RequestData(self)"
        panel_visibility="never">
        <Hints>
         <Widget type="multi_line"/>
        </Hints>
      <Documentation>This property contains the text of a python program that
      the programmable source runs.</Documentation>
      </StringVectorProperty>

      <StringVectorProperty
        name="InformationScript"
        command="SetInformationScript"
        number_of_elements="1"
        default_values="import threading&#xA;import paraview.simple &#xA;import os&#xA;import sys&#xA;import numpy as np&#xA;from vtk.util import numpy_support&#xA;import vtk&#xA;from contextlib import contextmanager&#xA;from collections import namedtuple&#xA;import traceback&#xA;&#xA;&#xA;'''&#xA;Simple timer.&#xA;'''&#xA;import time&#xA;&#xA;class timewith():&#xA;    def __init__(self, name=''):&#xA;        self.name = name&#xA;        self.start = time.time()&#xA;&#xA;    @property&#xA;    def elapsed(self):&#xA;        return time.time() - self.start&#xA;&#xA;    def checkpoint(self, name=''):&#xA;        print '{timer} {checkpoint} took {elapsed} seconds'.format(&#xA;            timer=self.name,&#xA;            checkpoint=name,&#xA;            elapsed=self.elapsed,&#xA;        ).strip()&#xA;&#xA;    def __enter__(self):&#xA;        return self&#xA;&#xA;    def __exit__(self, type, value, traceback):&#xA;        self.checkpoint('finished')&#xA;        pass&#xA;&#xA;'''&#xA;Class for reading Eclipse files and producing Paraview datasets.&#xA;Attributes:&#xA;  self.egrid_header - directory with type definitions for various eclipse headers&#xA;  self.out - output object of the Programmable Filter, to avoid deep copies we store all&#xA;      auxiliary data directly here&#xA;  &#xA;  self.times - times of the restart file; set by RequestInformation&#xA;  self.file_names - file names named tuple with fields egrid and unrst. Set by SetFileName &#xA;  self.grid - egrid data; set by read_egrid&#xA;  self.restart - array of data for time steps in UNRST file; set by read_restart&#xA;  self.output - VTK output object, set by ExtractFilterOutput&#xA;'''&#xA;class EclipseIO :&#xA;  &#xA;    '''&#xA;    Running guard&#xA;    '''&#xA;    @contextmanager&#xA;    def running_guard(self, persistent_object):&#xA;        #print persistent_object, hasattr(persistent_object,'Running')&#xA;        if not hasattr(persistent_object,'Running'):&#xA;            #print &quot;init false&quot;&#xA;            persistent_object.Running=False&#xA;         &#xA;        try:&#xA;            running=persistent_object.Running&#xA;            persistent_object.Running=True&#xA;            yield not running&#xA;        finally:&#xA;            #print &quot;set false&quot;&#xA;            persistent_object.Running=False&#xA;  &#xA;    VTK_HEXAHEDRON=12&#xA;    VTK_POLY_DATA=0&#xA;&#xA;    '''&#xA;    Set definitions of format headers with proper endian (default is big-endian).&#xA;    Call with endian='&lt;' for choosing little-endian.    &#xA;    '''&#xA;    def __init__(self, endian='&gt;'):&#xA;       &#xA;        '''&#xA;        dtype specification for every header is stored under &#xA;        its keyword in the egrid_header record.&#xA;        '''        &#xA;        self.types={'INTE':endian+'i4',&#xA;                    'DOUB':endian+'f8',&#xA;                    'LOGI':endian+'i4',&#xA;                    'CHAR':'a8',&#xA;                    'REAL':endian+'f',&#xA;                    'MESS':'a1'} # no data ??     &#xA;&#xA;        self.block_spec={} &#xA;             &#xA;        self.block_spec['FILEHEAD']=[int,&#xA;          'version',&#xA;          'release_year',&#xA;          'reserved_00',&#xA;          (4,'backward_compatibility_version'), # smallest version that can read the file&#xA;          'grid_type', # 0 - corner point; 1 - unstructured; 2 - hybrid&#xA;          'dual_porosity_model', # 0 - single porosity; 1 - dual porosity; 2 - dual permeability&#xA;          'original_grid_format',&#xA;          ]&#xA;        &#xA;        self.block_spec['MAPUNITS']=[str,'units']&#xA;        &#xA;        self.block_spec['MAPAXES ']=[float,          &#xA;          (0,'y_axis_end',2), # x,y coordinate tuple&#xA;          (0,'origin', 2),&#xA;          (0,'x_axis_end',2)&#xA;          ]&#xA;        &#xA;        self.block_spec['GRIDUNIT']=[str,&#xA;           (0,'units', 2)]&#xA;        &#xA;        # grid header for corner point grids&#xA;        self.block_spec['GRIDHEAD']=[int,&#xA;          'grid_type',&#xA;          (0,'dimensions',3), # (nx,ny,nz)&#xA;          'LGR_idx',&#xA;          (25,'numres'),&#xA;          'nseg',&#xA;          'ntheta',&#xA;          (0,'host_box',6) # (lower i, j, k, upper i, j, k)          &#xA;          ]&#xA;&#xA;        self.block_spec['BOXORIG ']=[int,(0,'origin_xyz',3)]&#xA;               &#xA;        self.block_spec['reservoir']=[int,&#xA;          'lower_k_bound', &#xA;          'upper_k_bound',&#xA;          'incomplete_circle',&#xA;          'isolate_reservoir',&#xA;          'lower_lateral_bound',&#xA;          'upper_lateral_bound',&#xA;          ] &#xA;               &#xA;        self.block_spec['SEQNUM  ']=[int,'file_sequence_number']&#xA;        &#xA;        self.block_spec['INTEHEAD']=[int,&#xA;          'creation_time',&#xA;          (3,'units_type'), # 1-metric, 2-field, 3-lab&#xA;          (9,'dimensions',3),&#xA;          (12,'n_active_cells'),&#xA;          (15,'i_phase'), # [1-oil, water, oil/water, gas, oil/gas. gas/water, oil/water/gas]&#xA;          (17,'n_wells'),                                                &#xA;          (18,'n_max_completitions_per_well'),&#xA;          (20,'n_max_wells_per_group'),&#xA;          (21,'n_max_groups'),&#xA;          (25,'n_data_per_well'), # in IWELL array&#xA;          (28,'n_words_per_well'), # n of 8-char words in ZWELL array&#xA;          (33,'n_data_per_completition'), # in ICON array&#xA;          (37,'n_data_per_group'), # in IGRP array&#xA;          (65,'date',3), # date of the report time&#xA;          (95,'program_id'),&#xA;          (176,'n_max_segmented_wells'),&#xA;          (177,'n_max_segments_per_well'),&#xA;          (179,'n_data_per segment') # in ISEG array&#xA;          ]&#xA;        &#xA;        self.block_spec['LOGIHEAD']=[int,&#xA;          (4,'radial_model_flag_300'), # for eclipse 300&#xA;          (5,'radial_model_flag_100'), # for eclipse 100&#xA;          (15,'dual_porosity_flag'),&#xA;          (31,'coal_bed_methane_flag')&#xA;          ]                                     &#xA;        &#xA;        self.block_spec['DOUBHEAD']=[float,'time_in_days'] # day of the report step&#xA;&#xA;        self.block_spec['well_data']=[int,&#xA;          (0,'wellhead_pos_ijk',3),  # well position; cell indices i,j,k&#xA;          'n_connections',              &#xA;          'i_group',&#xA;          'well_type', #1-producer; 2-oil injection; 3-water injection; 4-gass injection&#xA;          (11,'well_status'), # &gt;0 open; &lt;=0 shut&#xA;          (43,'i_LGR'),&#xA;          (49,'friction_flag'),&#xA;          (71, 'segment_well_number') # =0 for ordinary wells&#xA;          ]&#xA;&#xA;        self.block_spec['completion']=[int,&#xA;          'connection_index', # -IC if no in current LGR&#xA;          (0,'coordinates',3), # ijk ???&#xA;          (6,'status'), # connection status &gt;0 open, &lt;=0 shut&#xA;          (14, 'penetration_direction'), # 1=x, 2=y, 3=z, 4=fractured in x, 5=fractured in y&#xA;          (15, 'segment') # segment containing connection, 0- for multi segment wells&#xA;          ]&#xA;        &#xA;        # Every field is tuple (in_label, out_label, unit)&#xA;        solution_fields=[&#xA;          (&quot;PRESSURE&quot;, &quot;Pressure&quot;,&quot;&quot;),&#xA;          (&quot;SWAT&quot;,      &quot;WaterSat&quot;,&quot;&quot;),&#xA;          (&quot;SGAS&quot;,      &quot;GasSat&quot;,&quot;&quot;),&#xA;          (&quot;SOIL&quot;,      &quot;OilSat&quot;,&quot;&quot;),&#xA;          (&quot;RS&quot;,        &quot;GasOilRatio&quot;,&quot;&quot;),&#xA;          (&quot;RV&quot;,        &quot;OilGasRatio&quot;,&quot;&quot;),&#xA;          (&quot;OWC&quot;,       &quot;OilWaterContact&quot;,&quot;&quot;),&#xA;          (&quot;OGC&quot;,       &quot;OilGasContact&quot;,&quot;&quot;),&#xA;          (&quot;GWC&quot;,       &quot;GasWaterContact&quot;,&quot;&quot;),&#xA;          (&quot;OILAPI&quot;,    &quot;OilAPI&quot;,&quot;&quot;),&#xA;          (&quot;FIPOIL&quot;,    &quot;OilFIP&quot;,&quot;&quot;),&#xA;          (&quot;FIPGAS&quot;,    &quot;GasFIP&quot;,&quot;&quot;),&#xA;          (&quot;FIPWAT&quot;,    &quot;WaterFIP&quot;,&quot;&quot;),&#xA;          (&quot;OIL-POTN&quot;,  &quot;OilPotential&quot;,&quot;&quot;),&#xA;          (&quot;GAS-POTN&quot;,  &quot;GasPotential&quot;,&quot;&quot;),&#xA;          (&quot;WAT-POTN&quot;,  &quot;WaterPotential&quot;,&quot;&quot;),&#xA;          (&quot;POLYMER&quot;,   &quot;PolymerConc&quot;,&quot;&quot;),&#xA;          (&quot;PADS&quot;,      &quot;PolymerAdsorbedConc&quot;,&quot;&quot;),&#xA;          (&quot;XMF&quot;,       &quot;LiquidMoleFrac&quot;,&quot;&quot;),&#xA;          (&quot;YMF&quot;,       &quot;VaporMoleFrac&quot;,&quot;&quot;),&#xA;          (&quot;ZMF&quot;,       &quot;TotalMoleFrac&quot;,&quot;&quot;),&#xA;          (&quot;SSOL&quot;,      &quot;SolventSat&quot;,&quot;&quot;),&#xA;          (&quot;PBUB&quot;,      &quot;BubblePressure&quot;,&quot;&quot;),&#xA;          (&quot;PDEW&quot;,      &quot;DewPressure&quot;,&quot;&quot;),&#xA;          (&quot;SURFACT&quot;,   &quot;SurfaceInteraction&quot;,&quot;&quot;),&#xA;          (&quot;SURFADS&quot;,   &quot;AdsorbedSurfactant&quot;,&quot;&quot;),&#xA;          (&quot;SURFMAX&quot;,   &quot;MaxSurfactantConc&quot;,&quot;&quot;),&#xA;          (&quot;SURFCNM&quot;,   &quot;SurfactantCapilaryNumber&quot;,&quot;&quot;),&#xA;          (&quot;GGI&quot;,       &quot;GI_InjectedGasRatio&quot;,&quot;&quot;),&#xA;          (&quot;WAT-PRES&quot;,  &quot;WaterPressure&quot;,&quot;&quot;),&#xA;          (&quot;WAT_PRES&quot;,  &quot;WaterPressure&quot;,&quot;&quot;),&#xA;          (&quot;GAS-PRES&quot;,  &quot;GasPressure&quot;,&quot;&quot;),&#xA;          (&quot;GAS_PRES&quot;,  &quot;GasPressure&quot;,&quot;&quot;),&#xA;          (&quot;OIL-VISC&quot;,  &quot;OilViscosity&quot;,&quot;&quot;),&#xA;          (&quot;OIL_VISC&quot;,  &quot;OilViscosity&quot;,&quot;&quot;),&#xA;          (&quot;VOIL&quot;,      &quot;OilViscosity&quot;,&quot;&quot;),&#xA;          (&quot;WAT-VISC&quot;,  &quot;WaterViscosity&quot;,&quot;&quot;),&#xA;          (&quot;WAT_VISC&quot;,  &quot;WaterViscosity&quot;,&quot;&quot;),&#xA;          (&quot;VWAT&quot;,      &quot;WaterViscosity&quot;,&quot;&quot;),&#xA;          (&quot;GAS-VISC&quot;,  &quot;GasViscosity&quot;,&quot;&quot;),&#xA;          (&quot;GAS_VISC&quot;,  &quot;GasViscosity&quot;,&quot;&quot;),&#xA;          (&quot;VGAS&quot;,      &quot;GasViscosity&quot;,&quot;&quot;),&#xA;          (&quot;OIL-DEN&quot;,   &quot;OilDensity&quot;,&quot;&quot;),&#xA;          (&quot;OIL_DEN&quot;,   &quot;OilDensity&quot;,&quot;&quot;),&#xA;          (&quot;WAT-DEN&quot;,   &quot;WaterDensity&quot;,&quot;&quot;),&#xA;          (&quot;WAT_DEN&quot;,   &quot;WaterDensity&quot;,&quot;&quot;),&#xA;          (&quot;GAS-DEN&quot;,   &quot;GasDensity&quot;,&quot;&quot;),&#xA;          (&quot;GAS_DEN&quot;,   &quot;GasDensity&quot;,&quot;&quot;),&#xA;          (&quot;DRAINAGE&quot;,  &quot;DrainageRegionNumber&quot;,&quot;&quot;)&#xA;          ]&#xA;        self.solution_fields={}&#xA;        for item in solution_fields:&#xA;            (key,label,unit)=item&#xA;            self.solution_fields[key]=(label,unit)&#xA;    &#xA;    '''&#xA;    Delete whole class as it is after __init__. Namely delete all VTK objects.&#xA;    This is called only when file name has changed.&#xA;    '''&#xA;    def __del__(self):&#xA;        #? should I delete these?&#xA;        #del self.output.corners&#xA;        #del self.output.cells&#xA;        #del self.output.points&#xA;        del self.file_names&#xA;        pass&#xA;&#xA;    '''&#xA;    Get output object from the filter, check its type and store in self.&#xA;    '''&#xA;    def ExtractFilterOutput(self, program_filter):&#xA;        if not hasattr(self, &quot;output&quot;):&#xA;            multi_output = program_filter.GetOutput()&#xA;            if not multi_output.IsA(&quot;vtkMultiBlockDataSet&quot;):&#xA;                print &quot;Wrong output data type. Should be vtkMultiBlockDataSet.&quot;&#xA;                raise SystemExit&#xA;            self.output=multi_output        &#xA;        &#xA;        &#xA;    '''&#xA;    Separate filename base and creates filename for egrid file and restart&#xA;    file.&#xA;    '''&#xA;    def SetFileName(self, file_name):&#xA;        (base, ext)=os.path.splitext(file_name)&#xA;        egrid=base+&quot;.egrid&quot;&#xA;        unrst=base+&quot;.unrst&quot;&#xA;        if not os.path.isfile(egrid):&#xA;            egrid=None&#xA;        &#xA;        if not os.path.isfile(unrst):&#xA;            unrst=None&#xA;        FileNames=namedtuple('FileNames', 'egrid unrst')        &#xA;        self.file_names=FileNames(egrid, unrst)&#xA;    &#xA;    &#xA;    '''&#xA;    Search given 'keyword' in the given binary file 'f'.&#xA;    Seeks file 'f' to the first byte of  the keyword. &#xA;    Returns -1 on fail.&#xA;    Note that keywords for eclipse files are always upper case 8 character long.&#xA;    '''&#xA;    @staticmethod&#xA;    def skip_to_keyword(f, keyword):&#xA;        data_str=&quot;&quot;&#xA;        while True:&#xA;            new_data=f.read(1024*4)&#xA;            if (not new_data):&#xA;                return -1&#xA;            data_str += new_data &#xA;            pos=data_str.find(keyword)&#xA;            if (pos &gt;= 0):&#xA;                f.seek(-(len(data_str)-pos),os.SEEK_CUR)&#xA;                return 1&#xA;            else:&#xA;                data_str=data_str[len(data_str) - len(keyword):]&#xA;                &#xA;    &#xA;    '''&#xA;    Without parameters read the block and return tuple consisting of the &#xA;    block name and block data.&#xA;    &#xA;    If the keyword parameter is given check that the block has correct keyword.&#xA;    If yes, read the block to the array of appropriate type and return it.&#xA;    If no, seek back and return None.&#xA;    &#xA;    Arrays are stored in named block using Fortran UNFORMATED data format (unfortunately not standardized).&#xA;    It seems that the format is as follows:&#xA;    position    bytes           meaning&#xA;    0x0000      8               blockname&#xA;    0x0008      4               number of stored items&#xA;    0x000c      4               type signature of the items&#xA;    0x0010      4               0x10 ??&#xA;    0x0014      4               N - subblock size in bytes&#xA;    ...         N &#xA;                4               N - subblock size in bytes&#xA;    ...                         repetition of subblocks up to total number of items&#xA;                4               0x10 ??&#xA;    '''&#xA;    def read_array(self, f, keyword=None, check_type=None, check_size=None, optional=False):            &#xA;        in_keyword=f.read(8)&#xA;        if (keyword is not None and keyword!=in_keyword):&#xA;            if optional:&#xA;                f.seek(-8, os.SEEK_CUR)&#xA;                return None&#xA;            else:&#xA;                print &quot;Missing obligatory block: &quot;, keyword, &quot;have block: &quot;, in_keyword&#xA;                raise SystemExit&#xA;&#xA;        size=np.fromfile(f, dtype=np.dtype(self.types['INTE']), count=1 )[0]&#xA;        elem_type=np.fromfile(f, dtype=np.dtype('S4'), count=1 )[0]&#xA;        elem_dtype=np.dtype(self.types[elem_type]) # possibly catch KeyError exception&#xA;        &#xA;        if (check_type is not None): &#xA;            assert(self.types[check_type]==elem_dtype)&#xA;        if (check_size is not None):&#xA;            assert(check_size==size)&#xA;        f.read(4) # 0x10 block_code&#xA;        &#xA;        array=np.array([], dtype=elem_dtype)&#xA;        while (array.size &lt; size):&#xA;            n_bytes=np.fromfile(f, dtype=np.dtype(self.types['INTE']), count=1 )[0]&#xA;            string=f.read(n_bytes)&#xA;            array=np.append(array, np.fromstring(string, dtype=elem_dtype))&#xA;            n_bytes_end=np.fromfile(f, dtype=np.dtype(self.types['INTE']), count=1 )[0]             &#xA;            assert(n_bytes==n_bytes_end)                         &#xA;        f.read(4) # block_code 0x10&#xA;        &#xA;        if (keyword is None):&#xA;            return (in_keyword, array)&#xA;        else:  &#xA;            return array&#xA;             &#xA;    &#xA;    &#xA;    &#xA;    '''&#xA;    Numpy array wrapper which check validity of indices and slices &#xA;    and return None for an index out of the array.&#xA;    Further provides conversion for a dictionary.&#xA;    '''&#xA;    class Array:&#xA;      &#xA;        '''&#xA;        Construct from a one dim (numpy) array&#xA;        '''&#xA;        def __init__(self, np_array):&#xA;            self.array=np_array&#xA;            &#xA;        def __getitem__(self, key):&#xA;            if (isinstance(key, int)):&#xA;                if (key&gt;len(self.array)): return None&#xA;            elif (isinstance(key,slice)):&#xA;                if (key.stop&gt;len(self.array)): return None&#xA;            return self.array[key]  &#xA;&#xA;        '''&#xA;        Read a block by read_array and convert it to dictionary&#xA;        using specification is self.header[keyword]. One block&#xA;        specification is an array, where the first is singleton of type of &#xA;        produced dictionary items. Elements from input array are processed along with &#xA;        items of specification array assigning the values from the input array to the keys&#xA;        given by the specification array. Specification may contain also tuple (position, key),&#xA;        to give explicit position of the key in the input array. Position must be greater then current &#xA;        position in the input array effectively skip some of its elements.&#xA;        Position is numbered from 1. &#xA;        &#xA;        Examples:&#xA;        'name' - set key 'name' to current value&#xA;        (20,'name') - jump forward to position 20 and set that value to the key 'name'&#xA;        (0,'name') - same as simply 'name'&#xA;        (0,'name',3) - form numpy array from 3 following values and assign to the key 'name'&#xA;        (10,'name',3) - jump forward and form a numpy array ...&#xA;        &#xA;        Vector items are numpy arrays.&#xA;        '''&#xA;        def make_dict(self, spec):&#xA;            in_array=self.array&#xA;            if (in_array is None or len(in_array) is 0):&#xA;                return None&#xA;            assert( np.can_cast(type(in_array[0]), spec[0]) &#xA;                   or spec[0] == bool)  &#xA;            i_in_array=0&#xA;            &#xA;            result_dict={}&#xA;            for item in spec[1:]:&#xA;                vector_size=None # default are scalar values&#xA;                if type(item) is tuple:&#xA;                    position=item[0]-1&#xA;                    if (position&gt;0): &#xA;                        assert(position &gt;= i_in_array)&#xA;                        i_in_array=position               &#xA;                    key=item[1]&#xA;                    if len(item)==3:&#xA;                        vector_size=item[2]&#xA;                else:&#xA;                    key=item&#xA;                              &#xA;                              &#xA;                if (i_in_array &gt;= len(in_array)):&#xA;                    new_value=None&#xA;                else:    &#xA;                    if vector_size is None:&#xA;                        # scalar value&#xA;                        new_value=in_array[i_in_array]&#xA;                        i_in_array+=1&#xA;                    else:&#xA;                        # vector value&#xA;                        new_value=in_array[i_in_array:i_in_array+vector_size]&#xA;                        i_in_array+=vector_size                &#xA;                # print &quot;Item: &quot;, key, i_in_array, new_value&#xA;                result_dict[key]=new_value    &#xA;                &#xA;            return result_dict        &#xA;&#xA;    &#xA;    &#xA;    '''&#xA;    Read a block by read_array and convert it to dictionary&#xA;    using specification is self.header[keyword]. ..&#xA;    '''&#xA;    def read_dict(self,f,keyword, optional=False):&#xA;        spec=self.block_spec[keyword]&#xA;        in_array=self.read_array(f,keyword, optional=optional)&#xA;        return self.Array(in_array).make_dict(spec)        &#xA;&#xA;    '''&#xA;    Read a block by read_array and connects individual character octets into an&#xA;    array of strings.&#xA;    '''&#xA;    def read_string_array(self,f, keyword, n_strings, n_octets_per_string, optional=False):            &#xA;        octets=self.read_array(f, keyword, 'CHAR', n_strings*n_octets_per_string, optional)  &#xA;        octets.shape=(n_strings, n_octets_per_string)&#xA;        &#xA;        strings=n_strings*[&quot;&quot;]&#xA;        for i in xrange(n_strings):&#xA;            tmp_str=&quot;&quot;.join(octets[i])&#xA;            strings[i]=tmp_str.strip()&#xA;            &#xA;        return strings    &#xA;    &#xA;    '''&#xA;    Reads EGRID file with name given by parameter 'filename' and&#xA;    store it into (empty) output object given by 'pdo' parameter.&#xA;    Returns updated pdo object.&#xA;    '''&#xA;    def read_egrid(self):&#xA;        if not self.file_names.egrid:&#xA;            print &quot;No grid file. ABORT.&quot;&#xA;            raise SystemExit&#xA;          &#xA;        with open(self.file_names.egrid, 'rb') as f:&#xA;            # skip one int&#xA;            f.read(4)&#xA;            grid={}&#xA;            &#xA;            grid['filehead']=self.read_dict(f, &quot;FILEHEAD&quot;)&#xA;            grid['mapunits']=self.read_dict(f, &quot;MAPUNITS&quot;, optional=True)        &#xA;            grid['mapaxes']=self.read_dict(f,&quot;MAPAXES &quot;, optional=True)&#xA;            grid['grid_unit']=self.read_dict(f,&quot;GRIDUNIT&quot;, optional=True)&#xA;            &#xA;            grid['gridhead']=self.read_dict(f,&quot;GRIDHEAD&quot;)&#xA;            &#xA;            numres=grid['gridhead']['numres']&#xA;            #print &quot;Numres: &quot;, numres&#xA;            (nx,ny,nz) = grid['dimensions'] = grid['gridhead']['dimensions']            &#xA;            nlines=(nx+1)*(ny+1)*numres&#xA;&#xA;            grid['boxorig']=self.read_dict(f,&quot;BOXORIG &quot;, optional=True)       &#xA;            grid['lines']=self.read_array(f,&quot;COORD   &quot;, 'REAL', 6*nlines)&#xA;            grid['lines'].shape=(nlines,6)&#xA;            &#xA;            res_data=self.read_array(f,&quot;COORDSYS&quot;, 'INTE', 6*grid['gridhead']['numres'], optional=True)&#xA;            if (res_data):&#xA;                res_data.shape=(grid['gridhead']['numres'], 6)&#xA;                grid['reservoirs']=res_data&#xA;            &#xA;            grid['z_corners']=self.read_array(f,&quot;ZCORN   &quot;, 'REAL', 8*nx*ny*nz)&#xA;            active=self.read_array(f,&quot;ACTNUM  &quot;, 'INTE', nx*ny*nz, optional=True)&#xA;            if active is not None:             &#xA;                grid['active_cells']=(active==1) # create boolean array&#xA;                assert(active.size == nx*ny*nz)&#xA;            else:&#xA;                grid['active_cells']=None&#xA;            # 0-inactive, 1-active, 2-active fracture, 3-active matrix and fracture &#xA;            &#xA;            grid['coarsening']=self.read_array(f,&quot;CORSNUM &quot;, 'INTE', nx*ny*nz, optional=True) &#xA;            grid['hostcells']=self.read_array(f,&quot;HOSTNUM &quot;, 'INTE', nx*ny*nz, optional=True) #LGR only&#xA;            self.read_array(f,&quot;ENDGRID &quot;)&#xA;            &#xA;            assert(grid['lines'] != None)&#xA;            assert(grid['z_corners'] != None)&#xA;            &#xA;            #print &quot;LINES\n&quot;,lines&#xA;            #print &quot;CORNERS\n&quot;,z_corners&#xA;            self.grid=grid&#xA;        &#xA;&#xA;    '''&#xA;    Create corresponding VTK mesh in given output object, that&#xA;    should be vtkUnstructuredGrid. Takes data from self.grid &#xA;    and assumes that they persist. New data&#xA;    are created in provided object output.&#xA;    '''&#xA;    def create_grid(self):&#xA;        if not hasattr(self, &quot;grid&quot;):&#xA;            print &quot;Grid data not loaded.&quot;&#xA;            raise SystemExit&#xA;          &#xA;        if hasattr(self, &quot;vtk_grid&quot;):&#xA;            return self.vtk_grid&#xA;          &#xA;        output=vtk.vtkUnstructuredGrid()&#xA;&#xA;        # eclipse coordinate system:  &#xA;        #           / &#xA;        #  x  &lt;---|/&#xA;        #         |&#xA;        #         v z&#xA;        &#xA;        grid=self.grid&#xA;        (nx,ny,nz)=grid['dimensions']&#xA;        lines=grid['lines']&#xA;        z_corners=grid['z_corners']&#xA;        &#xA;        output.Reset()&#xA;        &#xA;        # number lines&#xA;        i_line=np.arange(lines.shape[0]).reshape((ny+1,nx+1))&#xA;        # distribute line numbers to corners in one X, Y layer&#xA;        # make them broadcastable to Z direction&#xA;        i_line=np.repeat( np.repeat(i_line, 2, axis=0), 2, axis=1)[1:-1, 1:-1].reshape(1,-1)&#xA;        assert(i_line.shape[1] == 2*nx*2*ny)&#xA;        # separate Z direction to use broadcasting of line numbers&#xA;        z_corners.shape=(-1, 2*nx*2*ny)&#xA;        assert(z_corners.shape[0]==2*nz)&#xA;        &#xA;        # interpolate X,Y of corners on lines&#xA;        z_line_top=lines[i_line,2]&#xA;        z_line_bot=lines[i_line,5]&#xA;        t= (z_corners - z_line_top)/(z_line_bot-z_line_top)&#xA;        x_corners=lines[i_line,0] - t*(lines[i_line,3] - lines[i_line,0])&#xA;        y_corners=lines[i_line,1] - t*(lines[i_line,4] - lines[i_line,1])&#xA;        &#xA;        # permute corners to individual cells&#xA;        corners=np.vstack( (x_corners.flatten(), y_corners.flatten(), z_corners.flatten())  )&#xA;        # permute corners on one cell into VTK numbering &#xA;        local_points=np.arange(24).reshape(2,4,3)[:,[0,1,3,2],:]&#xA;        corn=np.transpose(corners.reshape(3,nz,2,ny,2,nx,2), axes=(1,3,5,2,4,6,0)).reshape(nx*ny*nz, 24)[:,local_points]&#xA;        # compute cell centers for wells&#xA;        self.cell_centers=np.mean(corn.reshape(nz,ny,nx,8,3), axis=3)&#xA;        &#xA;        # possibly remove non-active cells&#xA;        active=grid['active_cells']&#xA;        if active is not None:&#xA;            output.corners=corn[active, :]&#xA;        else:&#xA;            output.corners=corn&#xA;        n_cells=output.corners.shape[0]            &#xA;        output.corners.shape=(8*n_cells, 3)                  &#xA;        &#xA;        # create cell to corner map&#xA;        output.cells=np.empty((n_cells,9), dtype=int)&#xA;        output.cells[:,0]=8&#xA;        output.cells[:,1:9]=np.arange(8*n_cells).reshape((-1,8))               &#xA;        output.cells.shape=(-1)        &#xA;        &#xA;        output.points=vtk.vtkPoints()&#xA;        output.points.SetData(numpy_support.numpy_to_vtk(output.corners)) # 8*nx*ny*nz (x,y,z)&#xA;        output.SetPoints(output.points)&#xA;        &#xA;        output.cell_array = vtk.vtkCellArray()&#xA;        output.cell_array.SetCells(n_cells, numpy_support.numpy_to_vtkIdTypeArray(output.cells)) # nx*ny*nz (n,8*i_point)&#xA;        output.SetCells(self.VTK_HEXAHEDRON, output.cell_array) &#xA;        &#xA;        self.vtk_grid=output&#xA;        &#xA;        return self.vtk_grid&#xA;        &#xA;       &#xA;        &#xA;    '''&#xA;    Read a restart file as an array of times&#xA;    self.restart[ step1, step2, ...]&#xA;    '''&#xA;    def read_restart(self):&#xA;        if not self.file_names.unrst:&#xA;            return&#xA;        &#xA;        with open(self.file_names.unrst, 'rb') as f:&#xA;            # skip one int&#xA;            f.read(4)&#xA;            self.restart=[]&#xA;            &#xA;            while (1):&#xA;                one_step={}&#xA;                one_step['seq_num']=self.read_dict(f,'SEQNUM  ')&#xA;                &#xA;                one_step['head']=self.read_dict(f,'INTEHEAD')&#xA;                &#xA;                one_step['head'].update(self.read_dict(f,'LOGIHEAD'))&#xA;                #print one_step['head']&#xA;                data=self.read_array(f,'DOUBHEAD') # !! much more complex then described, skip&#xA;                #print data&#xA;                #one_step['head'].update()&#xA;                &#xA;                n_groups=one_step['head']['n_max_groups']&#xA;                group_data_size=one_step['head']['n_data_per_group']&#xA;                n_wells_in_group=one_step['head']['n_max_wells_per_group']&#xA;                group_i_data=self.read_array(f,'IGRP    ', 'INTE', n_groups*group_data_size)&#xA;                group_i_data.shape=(n_groups, group_data_size)&#xA;                &#xA;                # first create array of groups with raw data&#xA;                group_data=[]&#xA;                for i_data in group_i_data:&#xA;                    one_group_data=self.Array(i_data)&#xA;                    data={}&#xA;                    childs=one_group_data[0:n_wells_in_group]&#xA;                    n_childs=one_group_data[n_wells_in_group]&#xA;                    data['childs']=childs[0:n_childs]&#xA;                    data['type']=one_group_data[n_wells_in_group+26]&#xA;                    # 0-well_group, 1-node_group (childs are groups), 2- satellite group, 3-slave group&#xA;                    data['level']=one_group_data[n_wells_in_group+27]&#xA;                    data['parent_group']=one_group_data[n_wells_in_group+28]                    &#xA;                    #print &quot;=====&quot;&#xA;                    #print data&#xA;                    #print &quot;-----&quot;&#xA;                    #print one_group_data[n_wells_in_group+29:]&#xA;                    group_data.append(data)&#xA;                &#xA;                self.read_array(f,'SGRP    ')&#xA;                self.read_array(f,'XGRP    ')&#xA;                &#xA;                # undocumented block with group names&#xA;                n_words_per_group_name=5 # seems that this is fixed constant                &#xA;                name_array=self.read_string_array(f,'ZGRP    ', n_groups, n_words_per_group_name)&#xA;                for i_group in xrange(n_groups):                    &#xA;                    group_data[i_group]['name']=name_array[i_group]&#xA;                    #print &quot;=====================&quot;, i_group&#xA;                    #print group_data[i_group]&#xA;                &#xA;                # create a tree from the raw group data&#xA;                #i_root=None&#xA;                #for i_grp in xrange(n_groups):&#xA;                #    data=group_data[i_grp]&#xA;                #    parent=data['parent_group']&#xA;                #    if parent==0 and data['group_level']==0:   &#xA;                #        i_root=parent-1&#xA;                #    group_data['subgroups']    &#xA;                &#xA;                one_step['group_data']=group_data &#xA;                &#xA;                '''&#xA;                n_seg_wells=one_step['n_max_segmented_wells']&#xA;                n_seg_per_well=one_step['n_max_segments_per_well']&#xA;                segment_data_size=one_step['n_data_per_segment']&#xA;                segments_data=self.read_array(f,'ISEG    ', np.types['INTE'], n_seg_wells*n_seg_per_well*segment_data_size)&#xA;                segments_data.shape(n_seg_wells,n_seg_per_well,segment_data_size)&#xA;                for well in segments_data:&#xA;                    for segment in well:&#xA;                        outlet_segment_number=segment[1]&#xA;                        branch_for_segment=segment[3]&#xA;                '''&#xA;                &#xA;                n_wells=one_step['head']['n_wells']&#xA;                well_data_size=one_step['head']['n_data_per_well']                &#xA;                wells_data=self.read_array(f,'IWEL    ', 'INTE', n_wells*well_data_size)&#xA;                wells_data.shape=(n_wells, well_data_size)&#xA;                wells=[]&#xA;                for well_data in wells_data:&#xA;                    wells.append(self.Array(well_data)&#xA;                                .make_dict(self.block_spec['well_data']))&#xA;                &#xA;                self.read_array(f,'SWEL    ')&#xA;                self.read_array(f,'XWEL    ')&#xA;                &#xA;                name_array=self.read_string_array(f,'ZWEL    ', n_wells, one_step['head']['n_words_per_well'])&#xA;                for i_well in xrange(n_wells):                    &#xA;                    wells[i_well]['name']=name_array[i_well]&#xA;                &#xA;                n_completion=one_step['head']['n_max_completitions_per_well']&#xA;                n_per_completion=one_step['head']['n_data_per_completition']&#xA;                completion_data=self.read_array(f,'ICON    ', 'INTE', n_wells*n_completion*n_per_completion)&#xA;                completion_data.shape=(n_wells, n_completion, n_per_completion)&#xA;                for i_well in xrange(n_wells):&#xA;                    completions=[]&#xA;                    for compl in completion_data[i_well]:&#xA;                        completions.append(self.Array(compl)&#xA;                                          .make_dict(self.block_spec['completion']))&#xA;                    wells[i_well]['completions']=completions&#xA;                            &#xA;                one_step['wells']=wells&#xA;                &#xA;                #self.read_array(f,'SCON    ')&#xA;                #self.read_array(f,'XCON    ')&#xA;                #self.read_array(f,'DLYTIM  ')&#xA;                #self.read_array(f,'IAAQ    ')&#xA;                #self.read_array(f,'SAAQ    ')&#xA;                #self.read_array(f,'XAAQ    ')&#xA;                #self.read_array(f,'ICAQNUM ')&#xA;                #self.read_array(f,'ICAQ    ')&#xA;                #self.read_array(f,'SCAQNUM ')&#xA;                #self.read_array(f,'SCAQ    ')&#xA;                #self.read_array(f,'ACAQNUM '))&#xA;                #self.read_array(f,'ACAQ    '))                        &#xA;                &#xA;                # hidden contains names of solution arrays that &#xA;                # are just internal and should not be post-processed&#xA;                # self.skip_to_keyword(f,'HIDDEN')&#xA;                # self.read_array(f,'HIDDEN  ') # skip&#xA;                #self.read_array(f,'ZTRACER ') # skip for now&#xA;&#xA;                # read data fields  &#xA;                self.skip_to_keyword(f,'STARTSOL')&#xA;                data1=f.read(24) # 'STARTSOL',0x0,'MESS',0x10,0x10&#xA;                &#xA;                key=&quot;&quot;&#xA;                fields=[]&#xA;                while (1):&#xA;                    (key,array)=self.read_array(f)&#xA;                    if (key == 'ENDSOL  '):&#xA;                        f.seek(-8,os.SEEK_CUR)&#xA;                        break&#xA;                    key=key.strip()&#xA;                    vtk_array=self.make_data_set(key, array)&#xA;                    if vtk_array:&#xA;                        fields.append( vtk_array )      &#xA;                one_step['fields']=fields    &#xA;                self.restart.append(one_step)&#xA;                &#xA;                #buff=str(f.read(4))&#xA;                #print &quot;buff:&quot;, buff&#xA;                #f.seek(-4,os.SEEK_CUR)&#xA;                if (self.skip_to_keyword(f,'SEQNUM  ') == -1):&#xA;                    break &#xA;            # end step loop&#xA;            &#xA;        &#xA;        &#xA;    '''&#xA;    Read only DOUBHEAD sections to retrieve output times.&#xA;    We also check SEQNUM section for consecutive sequence.&#xA;    '''&#xA;    def read_restart_times(self):&#xA;        if not self.file_names.unrst:&#xA;            self.times=[0]&#xA;            return&#xA;          &#xA;        with open(self.file_names.unrst, &quot;rb&quot;) as f:&#xA;            i_time=0&#xA;            times=[]&#xA;            while (1):&#xA;                eof=self.skip_to_keyword(f, 'SEQNUM')&#xA;                if (eof==-1):&#xA;                    break&#xA;                i_time+=1  &#xA;                seq_num=self.read_dict(f,'SEQNUM  ')['file_sequence_number']&#xA;                #if (i_time != seq_num):&#xA;                #    print &quot;Wrong sequence number&quot;, seq_num, &quot; at position &quot;, i_time&#xA;                #    raise AssertionError&#xA;                eof=self.skip_to_keyword(f, 'DOUBHEAD')&#xA;                if (eof==-1):&#xA;                    print &quot;No DOUBHEAD section after SEQNUM section.&quot;&#xA;                    raise AssertionError&#xA;                times.append(self.read_dict(f,'DOUBHEAD')['time_in_days']) &#xA;        self.times=times&#xA;                &#xA;&#xA;    '''&#xA;    '''&#xA;    def add_dataset_to_multiblock(self, multiblock, dataset, name):&#xA;        n=multiblock.GetNumberOfBlocks()&#xA;        multiblock.SetBlock(n, dataset)&#xA;        multiblock.GetMetaData(n).Set(multiblock.NAME(), name)&#xA;        &#xA;        &#xA;    '''&#xA;    Add new PointData to given vkUnstructuredGrid with given name&#xA;    and data in a numpy array. Assumes a grid &#xA;    '''&#xA;    def make_data_set(self, key, np_array):&#xA;        # check that key is known&#xA;        if self.solution_fields.has_key(key):&#xA;            name=self.solution_fields[key][0]&#xA;        else:&#xA;            return None&#xA;&#xA;        in_dtype=np_array.dtype&#xA;        if issubclass(in_dtype.type, np.number):&#xA;            if issubclass(in_dtype.type, np.integer):&#xA;                fixed_np_array=np_array.astype(np.dtype('i'))&#xA;                new_array=numpy_support.numpy_to_vtkIdTypeArray(fixed_np_array, deep=True)&#xA;            else:&#xA;                new_array=numpy_support.numpy_to_vtk(np_array.astype(np.dtype('d')), deep=True)&#xA;        else:&#xA;            return None  &#xA;        new_array.SetName(name)&#xA;        return new_array&#xA;&#xA;    '''&#xA;    Create vtkPolyData representing the wells.&#xA;    Input - restart data for current time step.&#xA;    '''&#xA;    def make_wells(self, one_step):   &#xA;        n_total_points=0&#xA;        &#xA;        wells=one_step['wells']        &#xA;        groups=one_step['group_data']&#xA;        n_groups=len(groups)&#xA;        &#xA;        out=vtk.vtkMultiBlockDataSet()&#xA;        for i_group in xrange(n_groups):&#xA;            group=groups[i_group]&#xA;            if not group['type'] == 0: # non-well group&#xA;                continue&#xA;                          &#xA;            # check well indices&#xA;            group_well_ids=[]&#xA;            for i_well in group['childs']:&#xA;                #if not wells[i_well-1]['i_group']==i_group+1:&#xA;                #    print &quot;Warning: well of a group do not point back&quot;, group['childs'], i_group, wells[i_well-1]['i_group']&#xA;                group_well_ids.append(i_well-1)&#xA;                    &#xA;            n_wells=len(group_well_ids)&#xA;            if n_wells==0:&#xA;                continue&#xA;            &#xA;            points=np.empty( (n_wells, 2, 3), dtype=self.cell_centers.dtype)&#xA;            lines=np.empty( (n_wells, 3), dtype='int64')&#xA;            labels=vtk.vtkStringArray()&#xA;            labels.SetName(&quot;label&quot;)&#xA;            for i_well in xrange(n_wells):                &#xA;                well=wells[ group_well_ids[i_well] ]&#xA;                head_pos=well['wellhead_pos_ijk']-1&#xA;                well_type=well['well_type'] #1-producer; 2-oil injection; 3-water injection; 4-gass injection&#xA;                well_status=well['well_status'] # &gt;0 open; &lt;=0 shut&#xA;                name=well['name']&#xA;                #connections=well['completions']&#xA;                '''&#xA;                for conect in connections:&#xA;                    pos=conect['coordinates'] # ijk cell &#xA;                    status=conect['status'] # connection status &gt;0 open, &lt;=0 shut&#xA;                '''&#xA;                # need cell centers for all cells&#xA;                #print self.cell_centers.shape&#xA;                #print head_pos &#xA;                head=self.cell_centers[head_pos[2]-1, head_pos[1]-1, head_pos[0],0:3]&#xA;                &#xA;                #print i_well&#xA;                #print head&#xA;                points[i_well,0,0:3]=head&#xA;                labels.InsertNextValue(&quot;&quot;)&#xA;                &#xA;                head_shift=head-np.array([0,0,100])&#xA;                points[i_well,1,0:3]=head_shift&#xA;                lines[i_well,0]=2&#xA;                lines[i_well,1]=2*i_well&#xA;                lines[i_well,2]=2*i_well+1&#xA;                labels.InsertNextValue(name)&#xA;                i_well+=1&#xA;            &#xA;            points.shape=(-1,3)&#xA;            lines.shape=(-1)&#xA;&#xA;            group_block=vtk.vtkPolyData()&#xA;            &#xA;            vtk_points=vtk.vtkPoints()&#xA;            vtk_points.SetData(numpy_support.numpy_to_vtk(points, deep=True))&#xA;            group_block.SetPoints(vtk_points)&#xA;            n_total_points+=points.shape[0]&#xA;            &#xA;            point_cells=vtk.vtkCellArray()   &#xA;            point_cells.SetCells(n_wells, numpy_support.numpy_to_vtkIdTypeArray(lines, deep=True))&#xA;            group_block.SetLines(point_cells)&#xA;            &#xA;            group_block.GetPointData().AddArray(labels)&#xA;            self.add_dataset_to_multiblock(out, group_block, group['name'])&#xA;            self.n_wells_poly_data_points=n_total_points&#xA;&#xA;        return out   &#xA;&#xA;&#xA;        &#xA;    '''&#xA;    Make datasets from all fields on input.&#xA;    '''&#xA;    def set_all_data_sets(self, one_step, output):&#xA;        for vtk_field in one_step['fields']:&#xA;            name=vtk_field.GetName()&#xA;            cell_data=output.GetCellData()&#xA;            output_array=cell_data.GetArray(name)&#xA;            #help(cell_data.GetArray)&#xA;            if output_array:&#xA;                # this possibly could be done better&#xA;                cell_data.RemoveArray(name)&#xA;                cell_data.AddArray(vtk_field)&#xA;            else:&#xA;                cell_data.AddArray(vtk_field)&#xA;            &#xA;    &#xA;    &#xA;    '''&#xA;    Setting information about the filter output.&#xA;    '''&#xA;    def RequestInformation(self, program_filter):&#xA;        try:&#xA;            with self.running_guard(program_filter) as r:&#xA;              if r:&#xA;                self.read_restart_times()&#xA;                self.np_times=np.array(self.times)&#xA;                &#xA;                executive=program_filter.GetExecutive()&#xA;                #help(executive.__class__)&#xA;                out_info=executive.GetOutputInformation(0)&#xA;                #out_info=executive.GetOutputInformation().GetInformationObject(0)&#xA;                out_info.Remove(executive.TIME_STEPS())&#xA;                for time in self.times:&#xA;                    out_info.Append(executive.TIME_STEPS(), time)&#xA;                    #out_info.Append(vtkStreamingDemandDrivePipeline.TIME_STEPS(), time)&#xA;                out_info.Remove(executive.TIME_RANGE())&#xA;                out_info.Append(executive.TIME_RANGE(), self.times[0])&#xA;                out_info.Append(executive.TIME_RANGE(), self.times[-1])&#xA;                #print out_info&#xA;                #print &quot;Times:&quot;, times&#xA;        except BaseException:&#xA;            print &quot;== Eclipse Reader Exception (RequestInfo) ==&quot;&#xA;            (et, ex, tr)=sys.exc_info()&#xA;            print &quot;Exception: &quot;, et, ex&#xA;            traceback.print_tb(tr)&#xA;                &#xA;            &#xA;    '''&#xA;    Get timestep to which we should set the data on the grid.&#xA;    '''&#xA;    def GetUpdateTimeStep(self, program_filter):&#xA;        # get requested timestep or the frist one if not present&#xA;        executive = program_filter.GetExecutive()&#xA;        out_info = executive.GetOutputInformation(0)&#xA;        #print out_info&#xA;        if not out_info.Has(executive.UPDATE_TIME_STEP()):&#xA;            return self.times[0]&#xA;        else:&#xA;            return out_info.Get(executive.UPDATE_TIME_STEP())&#xA;&#xA;            &#xA;    '''&#xA;    Setting data to the filter output&#xA;    '''&#xA;    def RequestData(self, program_filter):&#xA;        try:&#xA;            with self.running_guard(program_filter) as r:&#xA;              if r:&#xA;                if not hasattr(self, &quot;grid&quot;):&#xA;                    self.read_egrid() &#xA;                &#xA;                self.ExtractFilterOutput(program_filter)&#xA;                timestep=self.GetUpdateTimeStep(program_filter)&#xA;                &#xA;                # optionaly create the grid&#xA;                if not self.output.GetBlock(0):                              &#xA;                    self.output.SetBlock(0, self.create_grid() )&#xA;                    self.output.GetMetaData(0).Set(self.output.NAME(), &quot;eclipse grid&quot;);                    &#xA;                &#xA;                # optionaly read data&#xA;                if self.file_names.unrst:&#xA;                    if not hasattr(self, &quot;restart&quot;):&#xA;                        self.read_restart()&#xA;                &#xA;                    #find time&#xA;                    i_time=np.abs(self.np_times-timestep).argmin()&#xA;                    timestep=self.times[i_time]&#xA;                    # make datasets        &#xA;                    self.set_all_data_sets(self.restart[i_time], self.output.GetBlock(0))&#xA;                    # mark correct timestep &#xA;                    self.output.GetInformation().Set(self.output.DATA_TIME_STEP(), timestep)&#xA;&#xA;                    # create well groups  block  &#xA;                    self.add_dataset_to_multiblock(self.output, &#xA;                                                   self.make_wells(self.restart[i_time]),&#xA;                                                   &quot;eclipse well groups&quot;)&#xA;                    &#xA;&#xA;                # possibly reset camera to get correct view&#xA;                # need working recursion prevention&#xA;                # Finally it is done automaticaly but we may want other orientation of the system.&#xA;                #print &quot;reset camera&quot;&#xA;                #paraview.simple.ResetCamera()&#xA;                &#xA;                # Create BlockSelection (do not work)&#xA;                '''&#xA;                group_block_ids=[]                &#xA;                iterator = self.output.NewIterator()&#xA;                iterator.InitTraversal()&#xA;                while not iterator.IsDoneWithTraversal():&#xA;                    obj_type=iterator.GetCurrentDataObject().GetDataObjectType()&#xA;                    if  obj_type== self.VTK_POLY_DATA:&#xA;                        group_block_ids.append( iterator.GetCurrentFlatIndex() )&#xA;                    iterator.GoToNextItem()&#xA;                &#xA;                print group_block_ids&#xA;                self.group_block_ids=group_block_ids&#xA;&#xA;                #sel_source.FieldType=&quot;point&quot;&#xA;                &#xA;                #help(self.programmable_filter)&#xA;                #self.programmable_filter.SetSelectionInput(0, sel_source, 0)&#xA;                &#xA;                #paraview.simple.UpdatePipeline()&#xA;                source=paraview.simple.FindSource(self.reader_name)&#xA;                paraview.simple.SetActiveSource(source)&#xA;                &#xA;                sel_source=paraview.simple.BlockSelectionSource()&#xA;                sel_source.Blocks=group_block_ids&#xA;                &#xA;                rep=paraview.simple.Show()&#xA;                rep.SelectionPointLabelVisibility = 1&#xA;                rep.SelectionPointFieldDataArrayName = 'labels'&#xA;                rep.SelectionPointLabelFormat = '%s'&#xA;                #rep.SelectionPointSize = 0&#xA;                #rep.SelectionPointLabelColor = [1,1,1]&#xA;                print &quot;done RequestData&quot;&#xA;                '''&#xA;                #Merge to vtkPolyData&#xA;                              &#xA;                '''&#xA;                #print &quot;find source:&quot;, self.reader_name&#xA;                #paraview.simple.UpdatePipeline()&#xA;                source=paraview.simple.FindSource(self.reader_name)&#xA;                print source&#xA;                &#xA;                #print &quot;set active&quot;&#xA;                &#xA;&#xA;                #print &quot;make merged&quot;&#xA;                merged=paraview.simple.ProgrammableFilter()&#xA;                merged.Script=self.merge_groups_script&#xA;                merged.OutputDataSetType=0 # PolyData&#xA;                merged.Input=source&#xA;                &#xA;                &#xA;                print &quot;make selection&quot;                &#xA;                #n_points=merged.GetDataInformation().DataInformation.GetNumberOfPoints()&#xA;                n_points=self.n_wells_poly_data_points&#xA;                selection=paraview.simple.IDSelectionSource()&#xA;                IDs = []&#xA;                for i in range(n_points):&#xA;                    IDs.append(0L)&#xA;                    IDs.append(long(i))&#xA;                selection.IDs = IDs&#xA;                selection.FieldType=1&#xA;                merged.SetSelectionInput(0,selection,0)&#xA;&#xA;                &#xA;&#xA;                print &quot;Show&quot;  &#xA;                paraview.simple.SetActiveSource(merged)&#xA;                print paraview.simple.Show()&#xA;                reps=paraview.simple.GetRepresentations()&#xA;                for (rep_name, rep_id) in reps:&#xA;                    print (rep_name, rep_id)&#xA;                    if rep_name=='GeometryRepresentation2':&#xA;                        key=(rep_name, rep_id)&#xA;                rep=reps[key]&#xA;                print rep&#xA;                &#xA;                &#xA;                print &quot;setup selection&quot;  &#xA;                rep.SelectionPointFieldDataArrayName&#xA;                rep.SelectionPointFieldDataArrayName = 'label'&#xA;                rep.SelectionPointLabelColor = [0,0,0]&#xA;                rep.SelectionPointLabelFormat = &quot;%s&quot;&#xA;                rep.SelectionPointLabelVisibility = 1&#xA;                #rep.SelectionPointSize = 0&#xA;                #&#xA;&#xA;                #print &quot;run ResetCamera&quot;&#xA;                #paraview.simple.ResetCamera()&#xA;                print &quot;done&quot;&#xA;                '''&#xA;                &#xA;        except BaseException:&#xA;            print &quot;== Eclipse Reader Exception ==&quot;&#xA;            (et, ex, tr)=sys.exc_info()&#xA;            print &quot;Exception: &quot;, et, ex&#xA;            traceback.print_tb(tr)&#xA;            &#xA;            &#xA;            &#xA;            # clean output&#xA;            for i_block in range(self.output.GetNumberOfBlocks()):&#xA;                self.output.RemoveBlock(i_block)&#xA;                &#xA;&#xA;&#xA;      &#xA;if (not hasattr(self,&quot;info_done_event&quot;)):&#xA;    self.info_done_event=threading.Event()&#xA;      &#xA;# main RequestInformation script&#xA;# every internal data are stored in self.code&#xA;if hasattr(self, &quot;code&quot;):&#xA;    del self.code&#xA;&#xA;self.code=EclipseIO()&#xA;self.code.programmable_filter=self&#xA;self.code.SetFileName(FileName)&#xA;self.code.RequestInformation(self)&#xA;# indicator that RequestInformation is done&#xA;self.info_done_event.set()&#xA;&#xA;&#xA; "
        panel_visibility="never">
        <Hints>
         <Widget type="multi_line"/>
        </Hints>
      <Documentation>This property contains the text of a python program that
      the programmable source runs.</Documentation>
      </StringVectorProperty>
      
      <DoubleVectorProperty
        name="TimestepValues"
        information_only="1">
        <TimeStepsInformationHelper/>
        <Documentation>
          Available timestep values.
        </Documentation>  
      </DoubleVectorProperty>
      
      <Hints>
        <ReaderFactory extensions="egrid unrst EGRID UNRST"
                       file_description="Eclipse mesh File Format" />
      </Hints>
    </SourceProxy>
  </ProxyGroup>
</ServerManagerConfiguration>
